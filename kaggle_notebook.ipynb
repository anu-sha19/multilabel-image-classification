{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":74788,"databundleVersionId":8176112,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:48:28.348382Z","iopub.execute_input":"2024-11-24T15:48:28.348824Z","iopub.status.idle":"2024-11-24T15:48:28.354725Z","shell.execute_reply.started":"2024-11-24T15:48:28.348785Z","shell.execute_reply":"2024-11-24T15:48:28.353506Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Goal of the project \n\n# input an image from the test set\n# The model will output predicted labels (e.g., [1, 8, 19]).\n# These labels will then be mapped to a caption using:\n #- A pre-defined lookup table for captions associated with labels.\n #- or a text generation model \n\ntrain = '/kaggle/input/multi-label-classification-competition-2024/COMP5329S1A2Dataset/train.csv'\ntest = '/kaggle/input/multi-label-classification-competition-2024/COMP5329S1A2Dataset/test.csv'\nimage_dir = '/kaggle/input/multi-label-classification-competition-2024/COMP5329S1A2Dataset/data'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:48:29.708780Z","iopub.execute_input":"2024-11-24T15:48:29.709269Z","iopub.status.idle":"2024-11-24T15:48:29.715506Z","shell.execute_reply.started":"2024-11-24T15:48:29.709221Z","shell.execute_reply":"2024-11-24T15:48:29.714133Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"import re\nfrom io import StringIO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:48:31.211712Z","iopub.execute_input":"2024-11-24T15:48:31.212164Z","iopub.status.idle":"2024-11-24T15:48:31.217685Z","shell.execute_reply.started":"2024-11-24T15:48:31.212126Z","shell.execute_reply":"2024-11-24T15:48:31.216389Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"with open(train) as file:\n    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\ntrain_df = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:48:32.449475Z","iopub.execute_input":"2024-11-24T15:48:32.449878Z","iopub.status.idle":"2024-11-24T15:48:32.647999Z","shell.execute_reply.started":"2024-11-24T15:48:32.449844Z","shell.execute_reply":"2024-11-24T15:48:32.646822Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"with open(test) as file:\n    lines = [re.sub(r'([^,])\"(\\s*[^\\n])', r'\\1/\"\\2', line) for line in file]\ntest_df = pd.read_csv(StringIO(''.join(lines)), escapechar=\"/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:48:34.740708Z","iopub.execute_input":"2024-11-24T15:48:34.741147Z","iopub.status.idle":"2024-11-24T15:48:34.815387Z","shell.execute_reply.started":"2024-11-24T15:48:34.741110Z","shell.execute_reply":"2024-11-24T15:48:34.814104Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_df.head(20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:42:47.004873Z","iopub.execute_input":"2024-11-24T15:42:47.005274Z","iopub.status.idle":"2024-11-24T15:42:47.032331Z","shell.execute_reply.started":"2024-11-24T15:42:47.005235Z","shell.execute_reply":"2024-11-24T15:42:47.030990Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   ImageID   Labels                                            Caption\n0    0.jpg        1   Woman in swim suit holding parasol on sunny day.\n1    1.jpg     1 19  A couple of men riding horses on top of a gree...\n2    2.jpg        1  They are brave for riding in the jungle on tho...\n3    3.jpg   8 3 13  a black and silver clock tower at an intersect...\n4    4.jpg    8 3 7   A train coming to a stop on the tracks out side.\n5    5.jpg        1      A young man riding a skateboard into the air.\n6    6.jpg        5          A big airplane flying in the big blue sky\n7    7.jpg      1 4         A man riding a motor bike across a forest.\n8    8.jpg      8 3      There is a street lined with packed buildings\n9    9.jpg  1 18 15  A skate park next to a body of water and green...\n10  10.jpg        1  Woman cutting pizza with fork and knife sittin...\n11  11.jpg        1                a man and woman cut into a big cake\n12  12.jpg     1 15  A piece of cake and coffee are on an outdoor t...\n13  13.jpg      1 3  People gathered outside in a big field on a cl...\n14  14.jpg   1 13 7  A stop sign directs pedestrians as a train tra...\n15  15.jpg        1  a female in military uniform cutting a busines...\n16  16.jpg        1  Six snowboards are propped in the snow on a rail.\n17  17.jpg      3 5               a small airplane that is on a runway\n18  18.jpg    1 3 6       A female traveler leaning on a luggage cart.\n19  19.jpg     18 3       The dog is playing with his toy in the grass","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageID</th>\n      <th>Labels</th>\n      <th>Caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.jpg</td>\n      <td>1</td>\n      <td>Woman in swim suit holding parasol on sunny day.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.jpg</td>\n      <td>1 19</td>\n      <td>A couple of men riding horses on top of a gree...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.jpg</td>\n      <td>1</td>\n      <td>They are brave for riding in the jungle on tho...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.jpg</td>\n      <td>8 3 13</td>\n      <td>a black and silver clock tower at an intersect...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.jpg</td>\n      <td>8 3 7</td>\n      <td>A train coming to a stop on the tracks out side.</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5.jpg</td>\n      <td>1</td>\n      <td>A young man riding a skateboard into the air.</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6.jpg</td>\n      <td>5</td>\n      <td>A big airplane flying in the big blue sky</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.jpg</td>\n      <td>1 4</td>\n      <td>A man riding a motor bike across a forest.</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8.jpg</td>\n      <td>8 3</td>\n      <td>There is a street lined with packed buildings</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9.jpg</td>\n      <td>1 18 15</td>\n      <td>A skate park next to a body of water and green...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10.jpg</td>\n      <td>1</td>\n      <td>Woman cutting pizza with fork and knife sittin...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11.jpg</td>\n      <td>1</td>\n      <td>a man and woman cut into a big cake</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12.jpg</td>\n      <td>1 15</td>\n      <td>A piece of cake and coffee are on an outdoor t...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13.jpg</td>\n      <td>1 3</td>\n      <td>People gathered outside in a big field on a cl...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14.jpg</td>\n      <td>1 13 7</td>\n      <td>A stop sign directs pedestrians as a train tra...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15.jpg</td>\n      <td>1</td>\n      <td>a female in military uniform cutting a busines...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16.jpg</td>\n      <td>1</td>\n      <td>Six snowboards are propped in the snow on a rail.</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17.jpg</td>\n      <td>3 5</td>\n      <td>a small airplane that is on a runway</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18.jpg</td>\n      <td>1 3 6</td>\n      <td>A female traveler leaning on a luggage cart.</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>19.jpg</td>\n      <td>18 3</td>\n      <td>The dog is playing with his toy in the grass</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:42:47.033954Z","iopub.execute_input":"2024-11-24T15:42:47.034403Z","iopub.status.idle":"2024-11-24T15:42:47.047009Z","shell.execute_reply.started":"2024-11-24T15:42:47.034363Z","shell.execute_reply":"2024-11-24T15:42:47.045730Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     ImageID                                            Caption\n0  30000.jpg  A little girl waring a krispy kreme hat holdin...\n1  30001.jpg  A beautiful young woman holding an orange fris...\n2  30002.jpg  A group of people sitting on couch next to a c...\n3  30003.jpg         A person on a snowboard rides on the hill.\n4  30004.jpg  A man riding a skateboard with a helmet on in ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageID</th>\n      <th>Caption</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>30000.jpg</td>\n      <td>A little girl waring a krispy kreme hat holdin...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30001.jpg</td>\n      <td>A beautiful young woman holding an orange fris...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30002.jpg</td>\n      <td>A group of people sitting on couch next to a c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>30003.jpg</td>\n      <td>A person on a snowboard rides on the hill.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>30004.jpg</td>\n      <td>A man riding a skateboard with a helmet on in ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"len(train_df['Labels'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:42:47.048639Z","iopub.execute_input":"2024-11-24T15:42:47.049056Z","iopub.status.idle":"2024-11-24T15:42:47.070684Z","shell.execute_reply.started":"2024-11-24T15:42:47.048998Z","shell.execute_reply":"2024-11-24T15:42:47.069068Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"776"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"all_labels = train_df['Labels'].apply(lambda x: x.split()).explode().unique()\n\n# Checking how many unique labels exist (should be between 1 and 19, excluding 12)\nlen(all_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:42:47.072667Z","iopub.execute_input":"2024-11-24T15:42:47.073491Z","iopub.status.idle":"2024-11-24T15:42:47.118268Z","shell.execute_reply.started":"2024-11-24T15:42:47.073442Z","shell.execute_reply":"2024-11-24T15:42:47.116857Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"18"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"\nall_possible_labels = set(map(str, range(1, 20)))\nmissing_labels = all_possible_labels - set(all_labels)\n\n# Output the missing label\nmissing_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:42:47.121700Z","iopub.execute_input":"2024-11-24T15:42:47.122166Z","iopub.status.idle":"2024-11-24T15:42:47.131069Z","shell.execute_reply.started":"2024-11-24T15:42:47.122123Z","shell.execute_reply":"2024-11-24T15:42:47.129720Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'12'}"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nimport numpy as np\n # converting all the labels into a binary matrix\n\ntrain_df['Labels'] = train_df['Labels'].apply(lambda x: list(map(int, x.split())))\n\n# all classes (e.g., excluding class 12)\nall_classes = [i for i in range(1, 20) if i != 12]\n\n# binary matrix\nmlb = MultiLabelBinarizer(classes=all_classes)\nbinary_labels = mlb.fit_transform(train_df['Labels'])\n\nnp.save('train_labels.npy', binary_labels)\nprint(f\"Binary labels saved: {binary_labels.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:42:47.132881Z","iopub.execute_input":"2024-11-24T15:42:47.133404Z","iopub.status.idle":"2024-11-24T15:42:48.954973Z","shell.execute_reply.started":"2024-11-24T15:42:47.133355Z","shell.execute_reply":"2024-11-24T15:42:48.953598Z"}},"outputs":[{"name":"stdout","text":"Binary labels saved: (29996, 18)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"loaded_labels = np.load('train_labels.npy')\nprint(loaded_labels)\nprint(loaded_labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:42:48.956811Z","iopub.execute_input":"2024-11-24T15:42:48.957591Z","iopub.status.idle":"2024-11-24T15:42:48.969737Z","shell.execute_reply.started":"2024-11-24T15:42:48.957544Z","shell.execute_reply":"2024-11-24T15:42:48.968028Z"}},"outputs":[{"name":"stdout","text":"[[1 0 0 ... 0 0 0]\n [1 0 0 ... 0 0 1]\n [1 0 0 ... 0 0 0]\n ...\n [1 0 0 ... 0 0 0]\n [1 0 0 ... 0 0 0]\n [1 0 0 ... 0 0 0]]\n(29996, 18)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"sample_index = 0  # checking for image 1 \nprint(\"Original Labels:\", train_df['Labels'][sample_index])\nprint(\"Binary Representation:\", binary_labels[sample_index])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:42:48.971369Z","iopub.execute_input":"2024-11-24T15:42:48.971755Z","iopub.status.idle":"2024-11-24T15:42:48.980711Z","shell.execute_reply.started":"2024-11-24T15:42:48.971721Z","shell.execute_reply":"2024-11-24T15:42:48.979592Z"}},"outputs":[{"name":"stdout","text":"Original Labels: [1]\nBinary Representation: [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Pre-processing the images\n\n# Defines a preprocessing pipeline to resize images to 224x224, \n#convert them to tensors, and normalize pixel values using standard ImageNet mean and standard deviation.\n# Reads and processes each image from the image_dir using the pipeline\n# Stacks all processed image tensors into a single tensor\n# Save the preprocessed images as a file\n# Prints progress after every 1,000 images for monitoring.\n\n# from torchvision import transforms\n# from PIL import Image\n# import torch\n# import os\n\n# # preprocessing pipeline\n# image_transform = transforms.Compose([\n#     transforms.Resize((224, 224)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n# ])\n\n# # Preprocessing the training images\n# def preprocess_images(image_dir, filenames, output_file):\n#     image_data = []\n#     for idx, img_name in enumerate(filenames):\n#         img_path = os.path.join(image_dir, img_name)\n#         img_tensor = image_transform(Image.open(img_path).convert('RGB'))\n#         image_data.append(img_tensor)\n\n#         if idx % 1000 == 0:\n#             print(f\"Processed {idx}/{len(filenames)} images...\")\n    \n#     image_data = torch.stack(image_data)\n#     torch.save(image_data, output_file)\n#     print(f\"Images saved to {output_file}\")\n\n# train_filenames = train_df['ImageID'].tolist()\n# preprocess_images(image_dir, train_filenames, 'preprocessed_train_images.pt')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:42:48.982316Z","iopub.execute_input":"2024-11-24T15:42:48.982722Z"}},"outputs":[{"name":"stdout","text":"Processed 0/29996 images...\nProcessed 1000/29996 images...\nProcessed 2000/29996 images...\nProcessed 3000/29996 images...\nProcessed 4000/29996 images...\nProcessed 5000/29996 images...\nProcessed 6000/29996 images...\nProcessed 7000/29996 images...\nProcessed 8000/29996 images...\nProcessed 9000/29996 images...\nProcessed 10000/29996 images...\nProcessed 11000/29996 images...\nProcessed 12000/29996 images...\nProcessed 13000/29996 images...\nProcessed 14000/29996 images...\nProcessed 15000/29996 images...\nProcessed 16000/29996 images...\nProcessed 17000/29996 images...\nProcessed 18000/29996 images...\nProcessed 19000/29996 images...\nProcessed 20000/29996 images...\nProcessed 21000/29996 images...\nProcessed 22000/29996 images...\nProcessed 23000/29996 images...\nProcessed 24000/29996 images...\nProcessed 25000/29996 images...\nProcessed 26000/29996 images...\nProcessed 27000/29996 images...\nProcessed 28000/29996 images...\nProcessed 29000/29996 images...\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# # Preprocessinf the  test images\n# test_filenames = test_df['ImageID'].tolist()\n# preprocess_images(image_dir, test_filenames, 'preprocessed_test_images.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:50:20.480588Z","iopub.execute_input":"2024-11-24T15:50:20.481088Z","iopub.status.idle":"2024-11-24T15:50:20.486676Z","shell.execute_reply.started":"2024-11-24T15:50:20.481044Z","shell.execute_reply":"2024-11-24T15:50:20.485372Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import os\nimport torch\nfrom torchvision import transforms\nfrom PIL import Image\n# processing all images at once caused the kernel to restart again and again\n# so doing it in chunks of 5000 images at a time.\n\n# preprocessing pipeline\nimage_transform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize\n    transforms.ToTensor(),          # Convert to tensor\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n])\n\ndef preprocess_images_in_chunk(image_dir, filenames, chunk_size, output_dir):\n    \"\"\"\n    Preprocess images in smaller chunks and save each chunk separately.\n    Args:\n        image_dir: Path to the folder containing images.\n        filenames: List of image filenames to process.\n        chunk_size: Number of images to process in one chunk.\n        output_dir: Directory to save the preprocessed chunks.\n    \"\"\"\n    os.makedirs(output_dir, exist_ok=True)\n    total_files = len(filenames)\n    \n    for start_idx in range(0, total_files, chunk_size):\n        end_idx = min(start_idx + chunk_size, total_files)\n        chunk_filenames = filenames[start_idx:end_idx]\n        \n        image_data = []\n        for img_name in chunk_filenames:\n            img_path = os.path.join(image_dir, img_name)\n            img_tensor = image_transform(Image.open(img_path).convert('RGB'))\n            image_data.append(img_tensor)\n        \n        # Save the current chunk\n        chunk_file = os.path.join(output_dir, f'preprocessed_images_{start_idx}_{end_idx}.pt')\n        torch.save(torch.stack(image_data), chunk_file)\n        print(f\"Saved chunk {start_idx}-{end_idx} to {chunk_file}\")\n\n\ntrain_filenames = train_df['ImageID'].tolist()\nchunk_size = 5000  # Process 5,000 images at a time\noutput_dir = './preprocessed_train_chunks'\n\npreprocess_images_in_chunks(image_dir, train_filenames, chunk_size, output_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:55:09.303583Z","iopub.execute_input":"2024-11-24T15:55:09.305661Z","iopub.status.idle":"2024-11-24T16:00:09.207865Z","shell.execute_reply.started":"2024-11-24T15:55:09.305576Z","shell.execute_reply":"2024-11-24T16:00:09.205707Z"}},"outputs":[{"name":"stdout","text":"Saved chunk 0-5000 to ./preprocessed_train_chunks/preprocessed_images_0_5000.pt\nSaved chunk 5000-10000 to ./preprocessed_train_chunks/preprocessed_images_5000_10000.pt\nSaved chunk 10000-15000 to ./preprocessed_train_chunks/preprocessed_images_10000_15000.pt\nSaved chunk 15000-20000 to ./preprocessed_train_chunks/preprocessed_images_15000_20000.pt\nSaved chunk 20000-25000 to ./preprocessed_train_chunks/preprocessed_images_20000_25000.pt\nSaved chunk 25000-29996 to ./preprocessed_train_chunks/preprocessed_images_25000_29996.pt\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}